import streamlit as st
import pandas as pd
import os
from dotenv import load_dotenv

# Importera dina egna moduler (justera s칬kv칛gar vid behov)
from llm_core.interaction import (
    get_gemini_model,
    determine_intention, # Antag att denna funktion finns och 칛r redo
    get_llm_response_to_query_with_rag_WITHOUT_db,
    get_llm_response_to_query_without_rag_or_db,
    get_sql_from_llm,
    # 칐verv칛g en funktion f칬r att summera DataFrame med LLM
    # def summarize_dataframe_with_llm(model, dataframe, query): ...
)
from llm_core.db_executor import (
    get_db_connection, # Ska returnera en DuckDB-anslutning
    get_schema,
    execute_sql_query
)
from rag_pipeline.setup_embedding_db import (
    load_vector_store, # Laddar FAISS-index
    get_similar_docs
)

# F칬r moderna UI-komponenter (om du vill anv칛nda dem mer)
try:
    from streamlit_shadcn_ui import slider, input, textarea, button, switch, alert, card, tabs # Exempel
    import streamlit_shadcn_ui as sui # F칬r att kalla funktioner som sui.button etc.
    shadcn_available = True
except ImportError:
    shadcn_available = False
    st.warning("streamlit-shadcn-ui 칛r inte installerad. Vissa UI-element kan se annorlunda ut.")

# Ladda milj칬variabler (t.ex. GEMINI_API_KEY)
load_dotenv()

# --- Konfiguration och Initialisering (cachas) ---
@st.cache_resource # Viktigt f칬r prestanda
def initialize_agent_components():
    """
    Initialiserar och returnerar de n칬dv칛ndiga komponenterna f칬r agenten.
    """
    try:
        model = get_gemini_model() # Din funktion f칬r att h칛mta Gemini-modellen
    except Exception as e:
        st.error(f"Kunde inte ladda Gemini-modellen: {e}")
        st.stop()
        return None, None, None

    try:
        vector_store = load_vector_store() # Din funktion f칬r att ladda FAISS-index
        if vector_store is None:
            st.warning("Kunde inte ladda FAISS vector store. RAG-funktionalitet kommer att vara begr칛nsad.")
    except Exception as e:
        st.error(f"Fel vid laddning av FAISS vector store: {e}")
        vector_store = None


    db_schema_info = None
    try:
        # H칛mta databasschema f칬r text-to-SQL
        # Du kan beh칬va anpassa detta f칬r att f친 ett koncis och anv칛ndbart schema f칬r LLM:en
        conn = get_db_connection()
        if conn:
            db_schema_info = get_schema(conn, format_for_llm=True) # Antag att get_schema kan formatera f칬r LLM
            conn.close()
        else:
            st.warning("Kunde inte ansluta till databasen. SQL-funktionalitet kommer att vara begr칛nsad.")
    except Exception as e:
        st.error(f"Fel vid h칛mtning av databasschema: {e}")
        db_schema_info = None # S칛kerst칛ll att den 칛r None om fel uppst친r

    return model, vector_store, db_schema_info

# Ladda komponenter
llm_model, faiss_vector_store, db_schema = initialize_agent_components()

# --- Huvudfunktion f칬r JobbAgenten Dashboard ---
def job_agent_dashboard():
    """
    Huvudfunktionen som renderar JobbAgentens dashboard och hanterar interaktioner.
    """
    st.set_page_config(layout="wide", page_title="游뱄 JobbAgenten Deluxe", page_icon="游뱄")

    # Anpassad CSS (om du har en style.css och vill anv칛nda den)
    # try:
    #     with open("style.css") as f:
    #         st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)
    # except FileNotFoundError:
    #     pass # Ingen fara om filen inte finns

    if shadcn_available:
        cols = st.columns([0.8, 0.2])
        with cols[0]:
            st.title("游뱄 JobbAgenten Deluxe")
            st.caption("Din intelligenta assistent f칬r att utforska jobbannonser och datainsikter.")
        with cols[1]:
            if st.button("Rensa chatt", type="secondary", key="clear_chat_btn_main"):
                 st.session_state.messages = []
                 st.rerun()

    else:
        st.title("游뱄 JobbAgenten Deluxe")
        st.caption("Din intelligenta assistent f칬r att utforska jobbannonser och datainsikter.")
        if st.button("Rensa chatt"):
            st.session_state.messages = []
            st.rerun()


    # --- Initiera chatt-historik ---
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": "Hej! Hur kan jag hj칛lpa dig att utforska jobbannonser idag?"}
        ]

    # --- Visa chattmeddelanden ---
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            # Visa k칛llor om de finns
            if "sources" in message and message["sources"]:
                with st.expander("Visade k칛llor (RAG)", expanded=False):
                    for i, source_doc in enumerate(message["sources"]):
                        source_name = source_doc.metadata.get("source", f"K칛lla {i+1}")
                        if shadcn_available:
                            with card(key=f"source_card_{message['role']}_{i}"): # Unikt nyckel f칬r varje kort
                                st.subheader(f"游늯 {source_name}")
                                st.caption(f"Relevans: {source_doc.metadata.get('score', 'N/A'):.2f}" if isinstance(source_doc.metadata.get('score'), float) else "")
                                st.markdown(source_doc.page_content[:500] + "...") # Visa b칬rjan av texten
                        else:
                            st.markdown(f"**游늯 K칛lla: {source_name}**")
                            st.markdown(source_doc.page_content[:500] + "...")
                        st.divider()
            # Visa SQL-fr친ga om den finns
            if "sql_query" in message and message["sql_query"]:
                with st.expander("Genererad SQL-fr친ga", expanded=False):
                    st.code(message["sql_query"], language="sql")
            # Visa SQL-resultat om det finns
            if "sql_result" in message and message["sql_result"] is not None and not message["sql_result"].empty:
                with st.expander("Databasresultat", expanded=True):
                    st.dataframe(message["sql_result"])
                    # F칬rs칬k att automatiskt skapa ett diagram om det 칛r l칛mpligt
                    try_render_chart(message["sql_result"])


    # --- Anv칛ndarinput ---
    if prompt := st.chat_input("St칛ll din fr친ga h칛r... (t.ex. 'Vilka krav finns f칬r en systemutvecklare i Stockholm?' eller 'Visa antal jobb per stad')"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # --- Agentens logik ---
        with st.chat_message("assistant"):
            response_text = "Jag kunde tyv칛rr inte hitta ett svar."
            rag_sources = []
            generated_sql = None
            sql_results_df = pd.DataFrame() # Initiera som tom DataFrame
            
            # Anv칛nd st.status f칬r att visa vad som h칛nder
            with st.status("Bearbetar din fr친ga...", expanded=False) as status_indicator:
                if not llm_model:
                    st.error("LLM-modellen 칛r inte tillg칛nglig. Kan inte bearbeta fr친gan.")
                    st.session_state.messages.append({"role": "assistant", "content": "Ett internt fel uppstod (LLM ej laddad)."})
                    st.rerun()


                # 1. Best칛m intention (om funktionen finns och 칛r konfigurerad)
                status_indicator.update(label="Analyserar din fr친ga...")
                try:
                    # Du beh칬ver en bra prompt och logik f칬r `determine_intention`
                    # F칬r detta exempel, en f칬renklad logik:
                    if any(keyword in prompt.lower() for keyword in ["antal", "lista", "hur m친nga", "vilka jobb", "visa data", "databas"]):
                        intention = "SQL_QUERY"
                    elif faiss_vector_store: # Om vector store finns, anta RAG
                        intention = "RAG_QUERY"
                    else:
                        intention = "GENERAL_CONVERSATION"
                    st.write(f"Avsikt: {intention}") # F칬r debugging
                except Exception as e:
                    st.warning(f"Kunde inte best칛mma intention: {e}. Forts칛tter med RAG/Generell.")
                    intention = "RAG_QUERY" if faiss_vector_store else "GENERAL_CONVERSATION"


                # 2. Bearbeta baserat p친 intention
                if intention == "RAG_QUERY" and faiss_vector_store:
                    status_indicator.update(label="S칬ker i dokumentbasen (RAG)...")
                    try:
                        relevant_docs = get_similar_docs(faiss_vector_store, prompt, k=3)
                        if relevant_docs:
                            rag_sources = relevant_docs
                            response_text = get_llm_response_to_query_with_rag_WITHOUT_db(
                                model=llm_model,
                                query=prompt,
                                rag_context=relevant_docs
                            )
                        else:
                            status_indicator.update(label="Inga specifika dokument hittades, f칬rs칬ker svara generellt...")
                            response_text = get_llm_response_to_query_without_rag_or_db(llm_model, prompt)
                    except Exception as e:
                        st.error(f"Fel vid RAG-s칬kning: {e}")
                        response_text = "Ett fel uppstod n칛r jag s칬kte i dokumenten."

                elif intention == "SQL_QUERY" and db_schema:
                    status_indicator.update(label="F칬rs칬ker generera och k칬ra SQL-fr친ga...")
                    try:
                        generated_sql = get_sql_from_llm(
                            model=llm_model,
                            query=prompt,
                            db_schema=db_schema
                        )
                        if generated_sql:
                            st.write(f"Genererad SQL: {generated_sql}") # Debug
                            # (Valfritt) Fr친ga anv칛ndaren om bekr칛ftelse innan k칬rning
                            # if st.button("K칬r SQL-fr친ga?"): ...
                            conn = get_db_connection()
                            if conn:
                                sql_results_df, error_msg = execute_sql_query(conn, generated_sql, return_type='dataframe')
                                conn.close()
                                if error_msg:
                                    response_text = f"Kunde inte exekvera SQL: {error_msg}. F칬rs칬ker svara generellt ist칛llet."
                                    # Fallback till generell fr친ga om SQL misslyckas
                                    # response_text += "\n" + get_llm_response_to_query_without_rag_or_db(llm_model, prompt)
                                elif sql_results_df is not None and not sql_results_df.empty:
                                    # F칬rs칬k att f친 LLM att summera DataFrame
                                    status_indicator.update(label="Summerar databasresultat...")
                                    summary_prompt = f"Baserat p친 f칬ljande data fr친n databasen (som svar p친 fr친gan '{prompt}'), ge en kortfattad summering p친 svenska:\n\n{sql_results_df.to_string(index=False, max_rows=10)}\n\nSummering:"
                                    response_text = get_llm_response_to_query_without_rag_or_db(llm_model, summary_prompt)
                                    # response_text = f"Jag hittade f칬ljande data (visas nedan). {summary_llm}"
                                else:
                                    response_text = "SQL-fr친gan genererades och k칬rdes, men gav inget resultat. F칬rs칬ker svara generellt."
                                    # response_text += "\n" + get_llm_response_to_query_without_rag_or_db(llm_model, prompt)
                            else:
                                response_text = "Kunde inte ansluta till databasen f칬r att k칬ra SQL."
                        else:
                            response_text = "Kunde inte generera en SQL-fr친ga. F칬rs칬ker svara med RAG om m칬jligt."
                            if faiss_vector_store:
                                relevant_docs = get_similar_docs(faiss_vector_store, prompt, k=3)
                                if relevant_docs:
                                    rag_sources = relevant_docs
                                    response_text = get_llm_response_to_query_with_rag_WITHOUT_db(llm_model, prompt, relevant_docs)
                                else:
                                    response_text = get_llm_response_to_query_without_rag_or_db(llm_model, prompt)
                            else:
                                response_text = get_llm_response_to_query_without_rag_or_db(llm_model, prompt)

                    except Exception as e:
                        st.error(f"Fel vid SQL-hantering: {e}")
                        response_text = "Ett fel uppstod n칛r jag f칬rs칬kte interagera med databasen."

                else: # GENERAL_CONVERSATION eller fallback
                    status_indicator.update(label="Genererar ett allm칛nt svar...")
                    try:
                        response_text = get_llm_response_to_query_without_rag_or_db(llm_model, prompt)
                    except Exception as e:
                        st.error(f"Fel vid generering av allm칛nt svar: {e}")
                        response_text = "Ett fel uppstod n칛r jag f칬rs칬kte generera ett svar."
                
                status_indicator.update(label="F칛rdig!", state="complete", expanded=False)

            # Visa svaret och eventuell extra information
            st.markdown(response_text)
            if rag_sources:
                with st.expander("Visade k칛llor (RAG)", expanded=False):
                    for i, source_doc in enumerate(rag_sources):
                        source_name = source_doc.metadata.get("source", f"K칛lla {i+1}")
                        if shadcn_available:
                             with card(key=f"source_card_main_{i}"):
                                st.subheader(f"游늯 {source_name}")
                                st.caption(f"Relevans: {source_doc.metadata.get('score', 'N/A'):.2f}" if isinstance(source_doc.metadata.get('score'), float) else "")
                                st.markdown(source_doc.page_content[:500] + "...")
                        else:
                            st.markdown(f"**游늯 K칛lla: {source_name}**")
                            st.markdown(source_doc.page_content[:500] + "...")
                        st.divider()

            if generated_sql:
                with st.expander("Genererad SQL-fr친ga", expanded=False):
                    st.code(generated_sql, language="sql")
            if sql_results_df is not None and not sql_results_df.empty:
                with st.expander("Databasresultat", expanded=True):
                    st.dataframe(sql_results_df)
                    try_render_chart(sql_results_df)


            # Spara assistentens svar i historiken
            assistant_message = {"role": "assistant", "content": response_text}
            if rag_sources:
                assistant_message["sources"] = rag_sources
            if generated_sql:
                assistant_message["sql_query"] = generated_sql
            if sql_results_df is not None and not sql_results_df.empty:
                 assistant_message["sql_result"] = sql_results_df
            st.session_state.messages.append(assistant_message)
            # st.rerun() # Kan beh칬vas f칬r att uppdatera UI direkt, men kan ocks친 leda till dubbla k칬rningar. Testa.

def try_render_chart(df: pd.DataFrame):
    """
    F칬rs칬ker rendera ett Plotly-diagram om DataFrame 칛r l칛mplig.
    """
    if df.empty or len(df.columns) < 2:
        return

    # F칬renklad logik: f칬rs칬k skapa ett stapeldiagram om f칬rsta kolumnen 칛r kategorisk och andra numerisk
    try:
        # F칬rs칬k identifiera en kategorisk och en numerisk kolumn
        cat_col = None
        num_col = None

        for col in df.columns:
            if df[col].dtype == 'object' or pd.api.types.is_string_dtype(df[col]) or pd.api.types.is_categorical_dtype(df[col]):
                if df[col].nunique() < len(df): # Heuristik f칬r kategorisk
                    cat_col = col
                    break
        
        for col in df.columns:
            if pd.api.types.is_numeric_dtype(df[col]) and col != cat_col:
                num_col = col
                break
        
        if cat_col and num_col:
            # Sortera f칬r b칛ttre visualisering
            df_sorted = df.sort_values(by=num_col, ascending=False).head(15) # Visa topp 15
            
            # Anv칛nd Plotly Express f칬r enkelhet
            import plotly.express as px
            fig = px.bar(df_sorted, x=cat_col, y=num_col, title=f"{num_col} per {cat_col}",
                         color=cat_col, template="plotly_white")
            fig.update_layout(xaxis_title=cat_col, yaxis_title=num_col, showlegend=False)
            st.plotly_chart(fig, use_container_width=True)
            st.caption(f"Visualisering av de 15 fr칛msta resultaten f칬r '{num_col}' per '{cat_col}'.")

    except Exception as e:
        st.warning(f"Kunde inte automatiskt skapa ett diagram: {e}")


# --- K칬r dashboarden ---
if __name__ == "__main__":
    # Denna del k칬rs n칛r du k칬r `python din_fil.py`
    # Om du k칬r via `streamlit run din_fil.py`, s친 kommer Streamlit att hantera det.
    # `job_agent_dashboard()` kommer att anropas av Streamlit.
    # F칬r att denna sida ska fungera med `st_pages` i din `Start.py`,
    # beh칬ver `Start.py` peka p친 denna fil och funktionen `job_agent_dashboard`.
    # Om `Start.py` bara listar .py-filer i en mapp, se till att denna fil
    # inte har en `if __name__ == "__main__": job_agent_dashboard()` som st칬r.
    # Streamlit k칬r hela skriptet fr친n topp till botten.

    # Om du vill att denna fil ska vara den som k칬rs direkt med `streamlit run gemini.py`
    job_agent_dashboard()