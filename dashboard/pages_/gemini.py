import streamlit as st
import pandas as pd
import os
from dotenv import load_dotenv

# Importera dina egna moduler (justera s√∂kv√§gar vid behov)
from llm_core.interaction import (
    get_gemini_model,
    determine_intention, # Antag att denna funktion finns och √§r redo
    get_llm_response_to_query_with_rag_WITHOUT_db,
    get_llm_response_to_query_without_rag_or_db,
    get_sql_from_llm,
    # √ñverv√§g en funktion f√∂r att summera DataFrame med LLM
    # def summarize_dataframe_with_llm(model, dataframe, query): ...
)
from llm_core.db_executor import (
    get_db_connection, # Ska returnera en DuckDB-anslutning
    get_schema,
    execute_sql_query
)
from rag_pipeline.setup_embedding_db import (
    load_vector_store, # Laddar FAISS-index
    get_similar_docs
)

# F√∂r moderna UI-komponenter (om du vill anv√§nda dem mer)
try:
    from streamlit_shadcn_ui import slider, input, textarea, button, switch, alert, card, tabs # Exempel
    import streamlit_shadcn_ui as sui # F√∂r att kalla funktioner som sui.button etc.
    shadcn_available = True
except ImportError:
    shadcn_available = False
    st.warning("streamlit-shadcn-ui √§r inte installerad. Vissa UI-element kan se annorlunda ut.")

# Ladda milj√∂variabler (t.ex. GEMINI_API_KEY)
load_dotenv()

# --- Konfiguration och Initialisering (cachas) ---
@st.cache_resource # Viktigt f√∂r prestanda
def initialize_agent_components():
    """
    Initialiserar och returnerar de n√∂dv√§ndiga komponenterna f√∂r agenten.
    """
    try:
        model = get_gemini_model() # Din funktion f√∂r att h√§mta Gemini-modellen
    except Exception as e:
        st.error(f"Kunde inte ladda Gemini-modellen: {e}")
        st.stop()
        return None, None, None

    try:
        vector_store = load_vector_store() # Din funktion f√∂r att ladda FAISS-index
        if vector_store is None:
            st.warning("Kunde inte ladda FAISS vector store. RAG-funktionalitet kommer att vara begr√§nsad.")
    except Exception as e:
        st.error(f"Fel vid laddning av FAISS vector store: {e}")
        vector_store = None


    db_schema_info = None
    try:
        # H√§mta databasschema f√∂r text-to-SQL
        # Du kan beh√∂va anpassa detta f√∂r att f√• ett koncis och anv√§ndbart schema f√∂r LLM:en
        conn = get_db_connection()
        if conn:
            db_schema_info = get_schema(conn, format_for_llm=True) # Antag att get_schema kan formatera f√∂r LLM
            conn.close()
        else:
            st.warning("Kunde inte ansluta till databasen. SQL-funktionalitet kommer att vara begr√§nsad.")
    except Exception as e:
        st.error(f"Fel vid h√§mtning av databasschema: {e}")
        db_schema_info = None # S√§kerst√§ll att den √§r None om fel uppst√•r

    return model, vector_store, db_schema_info

# Ladda komponenter
llm_model, faiss_vector_store, db_schema = initialize_agent_components()

# --- Huvudfunktion f√∂r JobbAgenten Dashboard ---
def job_agent_dashboard():
    """
    Huvudfunktionen som renderar JobbAgentens dashboard och hanterar interaktioner.
    """
    st.set_page_config(layout="wide", page_title="ü§ñ JobbAgenten Deluxe", page_icon="ü§ñ")

    # Anpassad CSS (om du har en style.css och vill anv√§nda den)
    # try:
    #     with open("style.css") as f:
    #         st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)
    # except FileNotFoundError:
    #     pass # Ingen fara om filen inte finns

    if shadcn_available:
        cols = st.columns([0.8, 0.2])
        with cols[0]:
            st.title("ü§ñ JobbAgenten Deluxe")
            st.caption("Din intelligenta assistent f√∂r att utforska jobbannonser och datainsikter.")
        with cols[1]:
            if st.button("Rensa chatt", type="secondary", key="clear_chat_btn_main"):
                 st.session_state.messages = []
                 st.rerun()

    else:
        st.title("ü§ñ JobbAgenten Deluxe")
        st.caption("Din intelligenta assistent f√∂r att utforska jobbannonser och datainsikter.")
        if st.button("Rensa chatt"):
            st.session_state.messages = []
            st.rerun()


    # --- Initiera chatt-historik ---
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": "Hej! Hur kan jag hj√§lpa dig att utforska jobbannonser idag?"}
        ]

    # --- Visa chattmeddelanden ---
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            # Visa k√§llor om de finns
            if "sources" in message and message["sources"]:
                with st.expander("Visade k√§llor (RAG)", expanded=False):
                    for i, source_doc in enumerate(message["sources"]):
                        source_name = source_doc.metadata.get("source", f"K√§lla {i+1}")
                        if shadcn_available:
                            with card(key=f"source_card_{message['role']}_{i}"): # Unikt nyckel f√∂r varje kort
                                st.subheader(f"üìÑ {source_name}")
                                st.caption(f"Relevans: {source_doc.metadata.get('score', 'N/A'):.2f}" if isinstance(source_doc.metadata.get('score'), float) else "")
                                st.markdown(source_doc.page_content[:500] + "...") # Visa b√∂rjan av texten
                        else:
                            st.markdown(f"**üìÑ K√§lla: {source_name}**")
                            st.markdown(source_doc.page_content[:500] + "...")
                        st.divider()
            # Visa SQL-fr√•ga om den finns
            if "sql_query" in message and message["sql_query"]:
                with st.expander("Genererad SQL-fr√•ga", expanded=False):
                    st.code(message["sql_query"], language="sql")
            # Visa SQL-resultat om det finns
            if "sql_result" in message and message["sql_result"] is not None and not message["sql_result"].empty:
                with st.expander("Databasresultat", expanded=True):
                    st.dataframe(message["sql_result"])
                    # F√∂rs√∂k att automatiskt skapa ett diagram om det √§r l√§mpligt
                    try_render_chart(message["sql_result"])


    # --- Anv√§ndarinput ---
    if prompt := st.chat_input("St√§ll din fr√•ga h√§r... (t.ex. 'Vilka krav finns f√∂r en systemutvecklare i Stockholm?' eller 'Visa antal jobb per stad')"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # --- Agentens logik ---
        with st.chat_message("assistant"):
            response_text = "Jag kunde tyv√§rr inte hitta ett svar."
            rag_sources = []
            generated_sql = None
            sql_results_df = pd.DataFrame() # Initiera som tom DataFrame
            
            # Anv√§nd st.status f√∂r att visa vad som h√§nder
            with st.status("Bearbetar din fr√•ga...", expanded=False) as status_indicator:
                if not llm_model:
                    st.error("LLM-modellen √§r inte tillg√§nglig. Kan inte bearbeta fr√•gan.")
                    st.session_state.messages.append({"role": "assistant", "content": "Ett internt fel uppstod (LLM ej laddad)."})
                    st.rerun()


                # 1. Best√§m intention (om funktionen finns och √§r konfigurerad)
                status_indicator.update(label="Analyserar din fr√•ga...")
                try:
                    # Du beh√∂ver en bra prompt och logik f√∂r `determine_intention`
                    # F√∂r detta exempel, en f√∂renklad logik:
                    if any(keyword in prompt.lower() for keyword in ["antal", "lista", "hur m√•nga", "vilka jobb", "visa data", "databas"]):
                        intention = "SQL_QUERY"
                    elif faiss_vector_store: # Om vector store finns, anta RAG
                        intention = "RAG_QUERY"
                    else:
                        intention = "GENERAL_CONVERSATION"
                    st.write(f"Avsikt: {intention}") # F√∂r debugging
                except Exception as e:
                    st.warning(f"Kunde inte best√§mma intention: {e}. Forts√§tter med RAG/Generell.")
                    intention = "RAG_QUERY" if faiss_vector_store else "GENERAL_CONVERSATION"


                # 2. Bearbeta baserat p√• intention
                if intention == "RAG_QUERY" and faiss_vector_store:
                    status_indicator.update(label="S√∂ker i dokumentbasen (RAG)...")
                    try:
                        relevant_docs = get_similar_docs(faiss_vector_store, prompt, k=3)
                        if relevant_docs:
                            rag_sources = relevant_docs
                            response_text = get_llm_response_to_query_with_rag_WITHOUT_db(
                                model=llm_model,
                                query=prompt,
                                rag_context=relevant_docs
                            )
                        else:
                            status_indicator.update(label="Inga specifika dokument hittades, f√∂rs√∂ker svara generellt...")
                            response_text = get_llm_response_to_query_without_rag_or_db(llm_model, prompt)
                    except Exception as e:
                        st.error(f"Fel vid RAG-s√∂kning: {e}")
                        response_text = "Ett fel uppstod n√§r jag s√∂kte i dokumenten."

                elif intention == "SQL_QUERY" and db_schema:
                    status_indicator.update(label="F√∂rs√∂ker generera och k√∂ra SQL-fr√•ga...")
                    try:
                        generated_sql = get_sql_from_llm(
                            model=llm_model,
                            query=prompt,
                            db_schema=db_schema
                        )
                        if generated_sql:
                            st.write(f"Genererad SQL: {generated_sql}") # Debug
                            # (Valfritt) Fr√•ga anv√§ndaren om bekr√§ftelse innan k√∂rning
                            # if st.button("K√∂r SQL-fr√•ga?"): ...
                            conn = get_db_connection()
                            if conn:
                                sql_results_df, error_msg = execute_sql_query(conn, generated_sql, return_type='dataframe')
                                conn.close()
                                if error_msg:
                                    response_text = f"Kunde inte exekvera SQL: {error_msg}. F√∂rs√∂ker svara generellt ist√§llet."
                                    # Fallback till generell fr√•ga om SQL misslyckas
                                    # response_text += "\n" + get_llm_response_to_query_without_rag_or_db(llm_model, prompt)
                                elif sql_results_df is not None and not sql_results_df.empty:
                                    # F√∂rs√∂k att f√• LLM att summera DataFrame
                                    status_indicator.update(label="Summerar databasresultat...")
                                    summary_prompt = f"Baserat p√• f√∂ljande data fr√•n databasen (som svar p√• fr√•gan '{prompt}'), ge en kortfattad summering p√• svenska:\n\n{sql_results_df.to_string(index=False, max_rows=10)}\n\nSummering:"
                                    response_text = get_llm_response_to_query_without_rag_or_db(llm_model, summary_prompt)
                                    # response_text = f"Jag hittade f√∂ljande data (visas nedan). {summary_llm}"
                                else:
                                    response_text = "SQL-fr√•gan genererades och k√∂rdes, men gav inget resultat. F√∂rs√∂ker svara generellt."
                                    # response_text += "\n" + get_llm_response_to_query_without_rag_or_db(llm_model, prompt)
                            else:
                                response_text = "Kunde inte ansluta till databasen f√∂r att k√∂ra SQL."
                        else:
                            response_text = "Kunde inte generera en SQL-fr√•ga. F√∂rs√∂ker svara med RAG om m√∂jligt."
                            if faiss_vector_store:
                                relevant_docs = get_similar_docs(faiss_vector_store, prompt, k=3)
                                if relevant_docs:
                                    rag_sources = relevant_docs
                                    response_text = get_llm_response_to_query_with_rag_WITHOUT_db(llm_model, prompt, relevant_docs)
                                else:
                                    response_text = get_llm_response_to_query_without_rag_or_db(llm_model, prompt)
                            else:
                                response_text = get_llm_response_to_query_without_rag_or_db(llm_model, prompt)

                    except Exception as e:
                        st.error(f"Fel vid SQL-hantering: {e}")
                        response_text = "Ett fel uppstod n√§r jag f√∂rs√∂kte interagera med databasen."

                else: # GENERAL_CONVERSATION eller fallback
                    status_indicator.update(label="Genererar ett allm√§nt svar...")
                    try:
                        response_text = get_llm_response_to_query_without_rag_or_db(llm_model, prompt)
                    except Exception as e:
                        st.error(f"Fel vid generering av allm√§nt svar: {e}")
                        response_text = "Ett fel uppstod n√§r jag f√∂rs√∂kte generera ett svar."
                
                status_indicator.update(label="F√§rdig!", state="complete", expanded=False)

            # Visa svaret och eventuell extra information
            st.markdown(response_text)
            if rag_sources:
                with st.expander("Visade k√§llor (RAG)", expanded=False):
                    for i, source_doc in enumerate(rag_sources):
                        source_name = source_doc.metadata.get("source", f"K√§lla {i+1}")
                        if shadcn_available:
                             with card(key=f"source_card_main_{i}"):
                                st.subheader(f"üìÑ {source_name}")
                                st.caption(f"Relevans: {source_doc.metadata.get('score', 'N/A'):.2f}" if isinstance(source_doc.metadata.get('score'), float) else "")
                                st.markdown(source_doc.page_content[:500] + "...")
                        else:
                            st.markdown(f"**üìÑ K√§lla: {source_name}**")
                            st.markdown(source_doc.page_content[:500] + "...")
                        st.divider()

            if generated_sql:
                with st.expander("Genererad SQL-fr√•ga", expanded=False):
                    st.code(generated_sql, language="sql")
            if sql_results_df is not None and not sql_results_df.empty:
                with st.expander("Databasresultat", expanded=True):
                    st.dataframe(sql_results_df)
                    try_render_chart(sql_results_df)


            # Spara assistentens svar i historiken
            assistant_message = {"role": "assistant", "content": response_text}
            if rag_sources:
                assistant_message["sources"] = rag_sources
            if generated_sql:
                assistant_message["sql_query"] = generated_sql
            if sql_results_df is not None and not sql_results_df.empty:
                 assistant_message["sql_result"] = sql_results_df
            st.session_state.messages.append(assistant_message)
            # st.rerun() # Kan beh√∂vas f√∂r att uppdatera UI direkt, men kan ocks√• leda till dubbla k√∂rningar. Testa.

def try_render_chart(df: pd.DataFrame):
    """
    F√∂rs√∂ker rendera ett Plotly-diagram om DataFrame √§r l√§mplig.
    """
    if df.empty or len(df.columns) < 2:
        return

    # F√∂renklad logik: f√∂rs√∂k skapa ett stapeldiagram om f√∂rsta kolumnen √§r kategorisk och andra numerisk
    try:
        # F√∂rs√∂k identifiera en kategorisk och en numerisk kolumn
        cat_col = None
        num_col = None

        for col in df.columns:
            if df[col].dtype == 'object' or pd.api.types.is_string_dtype(df[col]) or pd.api.types.is_categorical_dtype(df[col]):
                if df[col].nunique() < len(df): # Heuristik f√∂r kategorisk
                    cat_col = col
                    break
        
        for col in df.columns:
            if pd.api.types.is_numeric_dtype(df[col]) and col != cat_col:
                num_col = col
                break
        
        if cat_col and num_col:
            # Sortera f√∂r b√§ttre visualisering
            df_sorted = df.sort_values(by=num_col, ascending=False).head(15) # Visa topp 15
            
            # Anv√§nd Plotly Express f√∂r enkelhet
            import plotly.express as px
            fig = px.bar(df_sorted, x=cat_col, y=num_col, title=f"{num_col} per {cat_col}",
                         color=cat_col, template="plotly_white")
            fig.update_layout(xaxis_title=cat_col, yaxis_title=num_col, showlegend=False)
            st.plotly_chart(fig, use_container_width=True)
            st.caption(f"Visualisering av de 15 fr√§msta resultaten f√∂r '{num_col}' per '{cat_col}'.")

    except Exception as e:
        st.warning(f"Kunde inte automatiskt skapa ett diagram: {e}")


# --- K√∂r dashboarden ---
if __name__ == "__main__":
    # Denna del k√∂rs n√§r du k√∂r `python din_fil.py`
    # Om du k√∂r via `streamlit run din_fil.py`, s√• kommer Streamlit att hantera det.
    # `job_agent_dashboard()` kommer att anropas av Streamlit.
    # F√∂r att denna sida ska fungera med `st_pages` i din `Start.py`,
    # beh√∂ver `Start.py` peka p√• denna fil och funktionen `job_agent_dashboard`.
    # Om `Start.py` bara listar .py-filer i en mapp, se till att denna fil
    # inte har en `if __name__ == "__main__": job_agent_dashboard()` som st√∂r.
    # Streamlit k√∂r hela skriptet fr√•n topp till botten.

    # Om du vill att denna fil ska vara den som k√∂rs direkt med `streamlit run gemini.py`
    job_agent_dashboard()